{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e47efa5e",
   "metadata": {},
   "source": [
    "### Imports and Model class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "95020db7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2b1667ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearRegressionModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.weights = nn.Parameter(torch.randn(1, requires_grad=True, dtype=torch.float))\n",
    "        self.bias = nn.Parameter(torch.randn(1, requires_grad=True, dtype=torch.float))\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        return self.weights * x + self.bias"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5aa2e7f",
   "metadata": {},
   "source": [
    "**Notes**:\n",
    "- `torch.nn` is the base package for everything neural networks, building computation graphs, etc.\n",
    "- `torch.nn.Module` is the base class extended to write your own neural networks. The class should initialize the required parameters (using `nn.Parameter` module) or using any of the pre-built layers as required.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43ce5cc9",
   "metadata": {},
   "source": [
    "### Make Predictions using PyTorch Inference mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d185d30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.3887, -1.7681,  1.5649,  1.1250, -0.2040, -1.3876, -0.5842, -0.0266,\n",
       "        -1.4381, -0.3459], requires_grad=True)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "tensor([ 0.2426, -1.7963,  1.3546,  0.9387, -0.3176, -1.4366, -0.6770, -0.1499,\n",
       "        -1.4843, -0.4518])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with torch.inference_mode(): # alternatively, use `torch.no_grad()` - this is from the older API.\n",
    "    m = LinearRegressionModel()\n",
    "    x = torch.randn(10, requires_grad=True, dtype=torch.float)\n",
    "    y = m(x)\n",
    "\n",
    "display(x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b18cd6c",
   "metadata": {},
   "source": [
    "### Train a *proper* model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6603ab93",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.L1Loss()\n",
    "optimizer = torch.optim.SGD(m.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa10b218",
   "metadata": {},
   "source": [
    "#### Training loop (and a testing loop?)\n",
    "\n",
    "1. Loop through the data\n",
    "2. Forward pass\n",
    "3. Calculate the loss\n",
    "4. Optimizer Zero grad\n",
    "5. Backprop - Traverse backward to calculate the gradients w.r.t the loss\n",
    "6. Gradient Descent - Adjust the parameters to improve the model based on teh calculated gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1b018f27",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42) # for reproducibility\n",
    "\n",
    "X, y = torch.randn(100, 1), torch.randn(100, 1)\n",
    "X_test = torch.randn(10, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "642c5743",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = LinearRegressionModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1b07a01",
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch_count = []\n",
    "loss_values = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9ef5cb28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/400, Loss: 1.6250\n",
      "Epoch 11/400, Loss: 1.6250\n",
      "Epoch 21/400, Loss: 1.6250\n",
      "Epoch 31/400, Loss: 1.6250\n",
      "Epoch 41/400, Loss: 1.6250\n",
      "Epoch 51/400, Loss: 1.6250\n",
      "Epoch 61/400, Loss: 1.6250\n",
      "Epoch 71/400, Loss: 1.6250\n",
      "Epoch 81/400, Loss: 1.6250\n",
      "Epoch 91/400, Loss: 1.6250\n",
      "Epoch 101/400, Loss: 1.6250\n",
      "Epoch 111/400, Loss: 1.6250\n",
      "Epoch 121/400, Loss: 1.6250\n",
      "Epoch 131/400, Loss: 1.6250\n",
      "Epoch 141/400, Loss: 1.6250\n",
      "Epoch 151/400, Loss: 1.6250\n",
      "Epoch 161/400, Loss: 1.6250\n",
      "Epoch 171/400, Loss: 1.6250\n",
      "Epoch 181/400, Loss: 1.6250\n",
      "Epoch 191/400, Loss: 1.6250\n",
      "Epoch 201/400, Loss: 1.6250\n",
      "Epoch 211/400, Loss: 1.6250\n",
      "Epoch 221/400, Loss: 1.6250\n",
      "Epoch 231/400, Loss: 1.6250\n",
      "Epoch 241/400, Loss: 1.6250\n",
      "Epoch 251/400, Loss: 1.6250\n",
      "Epoch 261/400, Loss: 1.6250\n",
      "Epoch 271/400, Loss: 1.6250\n",
      "Epoch 281/400, Loss: 1.6250\n",
      "Epoch 291/400, Loss: 1.6250\n",
      "Epoch 301/400, Loss: 1.6250\n",
      "Epoch 311/400, Loss: 1.6250\n",
      "Epoch 321/400, Loss: 1.6250\n",
      "Epoch 331/400, Loss: 1.6250\n",
      "Epoch 341/400, Loss: 1.6250\n",
      "Epoch 351/400, Loss: 1.6250\n",
      "Epoch 361/400, Loss: 1.6250\n",
      "Epoch 371/400, Loss: 1.6250\n",
      "Epoch 381/400, Loss: 1.6250\n",
      "Epoch 391/400, Loss: 1.6250\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(42) # for reproducibility\n",
    "epochs = 400\n",
    "\n",
    "# 1. Loop through the data\n",
    "for epoch in range(epochs):\n",
    "    m.train()  # Set the model to training mode\n",
    "    # 2. Forward pass\n",
    "    y_pred = m(X)\n",
    "    \n",
    "    # 3. Compute loss\n",
    "    loss = loss_fn(y_pred, y)\n",
    "    \n",
    "    # 4. Zero gradients\n",
    "    optimizer.zero_grad() # clear the gradients from the previous step (happens in step 6 from the previous epoch)\n",
    "\n",
    "    # 5. Backpropagation\n",
    "    loss.backward()\n",
    "    \n",
    "    # 6. Gradient Descent - Update weights\n",
    "    optimizer.step()\n",
    "\n",
    "    # 7. Print loss\n",
    "    if epoch % 10 == 0:\n",
    "        epoch_count.append(epoch)\n",
    "        loss_values.append(loss)\n",
    "        \n",
    "        print(f\"Epoch {epoch+1}/{epochs}, Loss: {loss.item():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "164e00f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 1.5558\n"
     ]
    }
   ],
   "source": [
    "m.eval()  # Set the model to evaluation mode\n",
    "with torch.inference_mode():\n",
    "    test_pred = m(torch.randn(10, 1))\n",
    "    test_loss = loss_fn(test_pred, X_test)\n",
    "    print(f\"Test Loss: {test_loss.item():.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "542022ed",
   "metadata": {},
   "source": [
    "### Saving and loading a PyTorch Model\n",
    "- `torch.save(MODEL_OBJ, PATH)` - Saves the PyTorch model object.\n",
    "- `torch.load(MODEL_OBJ, PATH)` - Loads the saved PyTorch model object.\n",
    "- `torch.nn.Module.load_state_dict()` - Loads the python dictionary that maps each layer(?) to it's parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5574fd43",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "MODEL_PATH = Path(\"first_model\")\n",
    "MODEL_PATH.mkdir(parents=True, exist_ok=True)\n",
    "MODEL_NAME = \"first_linear_regression_model.pth\" # conventionally, .pt or .pth is used for PyTorch models\n",
    "MODEL_SAVE_PATH = MODEL_PATH / MODEL_NAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8e0b4e75",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(obj=m.state_dict(), f=MODEL_SAVE_PATH) # save the model's state_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "235f6657",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m_reloaded = LinearRegressionModel() # create a new instance of the model\n",
    "m_reloaded.load_state_dict(torch.load(MODEL_SAVE_PATH)) # load the state_dict into the new model instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9c0dfb9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('weights', tensor([-0.4749])), ('bias', tensor([1.6640]))])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9bca8684",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('weights', tensor([-0.4749])), ('bias', tensor([1.6640]))])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m_reloaded.state_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60db31a0",
   "metadata": {},
   "source": [
    "### Putting it all back together (again!)\n",
    "\n",
    "*Writing a device agnostic code*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c770259",
   "metadata": {},
   "source": [
    "#### Imports and device setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eab6ced1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.6.0'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f4d25569",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed1a6218",
   "metadata": {},
   "source": [
    "#### 1. Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "206d6bd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "weight = 0.7\n",
    "bias = 0.3\n",
    "\n",
    "start = 0; end = 1; step = 0.02\n",
    "X = torch.arange(start, end, step).unsqueeze(dim=1).to(device)\n",
    "y = weight * X + bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "18637b2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([50, 1]), torch.Size([50, 1]))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ee491e1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([40, 1]),\n",
       " torch.Size([40, 1]),\n",
       " torch.Size([10, 1]),\n",
       " torch.Size([10, 1]))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_split = int(0.8 * len(X))\n",
    "X_train, y_train = X[:train_split], y[:train_split]\n",
    "X_test, y_test = X[train_split:], y[train_split:]\n",
    "\n",
    "X_train.shape, y_train.shape, X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cba4e408",
   "metadata": {},
   "source": [
    "#### 2. Build a PyTorch Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c45539c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearRegressionModelv2(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(in_features=1, out_features=1) # in_features = number of input features, out_features = number of output features\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        return self.linear(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "10641c29",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42) # for reproducibility\n",
    "model_v2 = LinearRegressionModelv2().to(device) # create an instance of the model and move it to the device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8f558d31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('linear.weight', tensor([[0.7645]])),\n",
       "             ('linear.bias', tensor([0.8300]))])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_v2.state_dict() # check the model's state_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b75743a7",
   "metadata": {},
   "source": [
    "#### 3. Train the model\n",
    "\n",
    "Needs:\n",
    "- Loss function\n",
    "- Optimizer\n",
    "- Training loop\n",
    "- Testing loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "40ef347d",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.L1Loss() # MAE loss function\n",
    "optimizer = torch.optim.SGD(params=model_v2.parameters(), lr=0.001) # SGD optimizer with learning rate of 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d17be5fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/400, Loss: 0.5552\n",
      "Test Loss: 0.5861\n",
      "Epoch 11/400, Loss: 0.5437\n",
      "Test Loss: 0.5726\n",
      "Epoch 21/400, Loss: 0.5321\n",
      "Test Loss: 0.5592\n",
      "Epoch 31/400, Loss: 0.5206\n",
      "Test Loss: 0.5457\n",
      "Epoch 41/400, Loss: 0.5091\n",
      "Test Loss: 0.5322\n",
      "Epoch 51/400, Loss: 0.4976\n",
      "Test Loss: 0.5187\n",
      "Epoch 61/400, Loss: 0.4861\n",
      "Test Loss: 0.5053\n",
      "Epoch 71/400, Loss: 0.4745\n",
      "Test Loss: 0.4918\n",
      "Epoch 81/400, Loss: 0.4630\n",
      "Test Loss: 0.4783\n",
      "Epoch 91/400, Loss: 0.4515\n",
      "Test Loss: 0.4649\n",
      "Epoch 101/400, Loss: 0.4400\n",
      "Test Loss: 0.4514\n",
      "Epoch 111/400, Loss: 0.4284\n",
      "Test Loss: 0.4379\n",
      "Epoch 121/400, Loss: 0.4169\n",
      "Test Loss: 0.4245\n",
      "Epoch 131/400, Loss: 0.4054\n",
      "Test Loss: 0.4110\n",
      "Epoch 141/400, Loss: 0.3939\n",
      "Test Loss: 0.3975\n",
      "Epoch 151/400, Loss: 0.3824\n",
      "Test Loss: 0.3840\n",
      "Epoch 161/400, Loss: 0.3708\n",
      "Test Loss: 0.3706\n",
      "Epoch 171/400, Loss: 0.3593\n",
      "Test Loss: 0.3571\n",
      "Epoch 181/400, Loss: 0.3478\n",
      "Test Loss: 0.3436\n",
      "Epoch 191/400, Loss: 0.3363\n",
      "Test Loss: 0.3302\n",
      "Epoch 201/400, Loss: 0.3248\n",
      "Test Loss: 0.3167\n",
      "Epoch 211/400, Loss: 0.3132\n",
      "Test Loss: 0.3032\n",
      "Epoch 221/400, Loss: 0.3017\n",
      "Test Loss: 0.2897\n",
      "Epoch 231/400, Loss: 0.2902\n",
      "Test Loss: 0.2763\n",
      "Epoch 241/400, Loss: 0.2787\n",
      "Test Loss: 0.2628\n",
      "Epoch 251/400, Loss: 0.2672\n",
      "Test Loss: 0.2493\n",
      "Epoch 261/400, Loss: 0.2556\n",
      "Test Loss: 0.2359\n",
      "Epoch 271/400, Loss: 0.2441\n",
      "Test Loss: 0.2224\n",
      "Epoch 281/400, Loss: 0.2326\n",
      "Test Loss: 0.2089\n",
      "Epoch 291/400, Loss: 0.2211\n",
      "Test Loss: 0.1954\n",
      "Epoch 301/400, Loss: 0.2096\n",
      "Test Loss: 0.1820\n",
      "Epoch 311/400, Loss: 0.1980\n",
      "Test Loss: 0.1685\n",
      "Epoch 321/400, Loss: 0.1865\n",
      "Test Loss: 0.1550\n",
      "Epoch 331/400, Loss: 0.1750\n",
      "Test Loss: 0.1416\n",
      "Epoch 341/400, Loss: 0.1635\n",
      "Test Loss: 0.1281\n",
      "Epoch 351/400, Loss: 0.1519\n",
      "Test Loss: 0.1146\n",
      "Epoch 361/400, Loss: 0.1404\n",
      "Test Loss: 0.1012\n",
      "Epoch 371/400, Loss: 0.1289\n",
      "Test Loss: 0.0877\n",
      "Epoch 381/400, Loss: 0.1174\n",
      "Test Loss: 0.0742\n",
      "Epoch 391/400, Loss: 0.1059\n",
      "Test Loss: 0.0607\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "\n",
    "epochs = 400\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model_v2.train() # set the model to training mode\n",
    "\n",
    "    y_pred = model_v2(X_train) # forward pass\n",
    "    loss = loss_fn(y_pred, y_train) # compute loss\n",
    "    optimizer.zero_grad() # zero gradients\n",
    "    loss.backward() # backpropagation\n",
    "    optimizer.step() # update weights\n",
    "    if epoch % 10 == 0:\n",
    "        print(f\"Epoch {epoch+1}/{epochs}, Loss: {loss.item():.4f}\")\n",
    "\n",
    "    model_v2.eval() # set the model to evaluation mode\n",
    "\n",
    "    with torch.inference_mode():\n",
    "        test_pred = model_v2(X_test)\n",
    "        test_loss = loss_fn(test_pred, y_test)\n",
    "        if epoch % 10 == 0:\n",
    "            print(f\"Test Loss: {test_loss.item():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "233d1a90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('linear.weight', tensor([[0.6085]])),\n",
       "             ('linear.bias', tensor([0.4300]))])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_v2.state_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b50ec2d",
   "metadata": {},
   "source": [
    "#### 4. Making predictions\n",
    "\n",
    "*Ideally, should be used on unseen data.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b649695e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.9168],\n",
       "        [0.9290],\n",
       "        [0.9412],\n",
       "        [0.9534],\n",
       "        [0.9655],\n",
       "        [0.9777],\n",
       "        [0.9899],\n",
       "        [1.0020],\n",
       "        [1.0142],\n",
       "        [1.0264]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_v2.eval()\n",
    "\n",
    "with torch.inference_mode():\n",
    "    y_pred = model_v2(X_test)\n",
    "\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "99f2a7dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.8600],\n",
       "        [0.8740],\n",
       "        [0.8880],\n",
       "        [0.9020],\n",
       "        [0.9160],\n",
       "        [0.9300],\n",
       "        [0.9440],\n",
       "        [0.9580],\n",
       "        [0.9720],\n",
       "        [0.9860]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6a35e46",
   "metadata": {},
   "source": [
    "#### Saving and load the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "78aeb0b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "MODEL_PATH = Path(\"first_model\")\n",
    "MODEL_PATH.mkdir(parents=True, exist_ok=True)\n",
    "MODEL_NAME = \"first_linear_regression_model_v2.pth\" # conventionally, .pt or .pth is used for PyTorch models\n",
    "MODEL_SAVE_PATH = MODEL_PATH / MODEL_NAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "04ec6fc3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('linear.weight', tensor([[0.6085]])),\n",
       "             ('linear.bias', tensor([0.4300]))])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.save(obj=model_v2.state_dict(), f=MODEL_SAVE_PATH) # save the model's state_dict\n",
    "model_v2_reloaded = LinearRegressionModelv2().to(device) # create a new instance of the model\n",
    "model_v2_reloaded.load_state_dict(torch.load(MODEL_SAVE_PATH)) # load the state_dict into the new model instance\n",
    "model_v2_reloaded.state_dict() # check the reloaded model's state_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ddd9a000",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('linear.weight', tensor([[0.6085]])),\n",
       "             ('linear.bias', tensor([0.4300]))])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_v2.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89e5b31a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torchenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
